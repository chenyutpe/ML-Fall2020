{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.loadtxt('hw6_train.dat')\n",
    "data_test = np.loadtxt('hw6_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.95632268  1.80130232 -0.560404   ...  1.15647158 -0.02457943\n",
      "   1.        ]\n",
      " [ 1.32397219 -2.40197608  2.00437315 ... -0.66552085 -0.2635734\n",
      "   1.        ]\n",
      " [ 1.41287312  2.51772309  1.81555809 ... -0.13231329 -0.41357255\n",
      "  -1.        ]\n",
      " ...\n",
      " [-3.54241785  1.90927013  0.03063317 ... -0.69957505  0.19560916\n",
      "   1.        ]\n",
      " [ 1.46852162 -2.35922982 -0.2427209  ... -0.57478285  0.23606362\n",
      "   1.        ]\n",
      " [ 3.45467048 -1.04328297  1.87407764 ... -0.51747156  1.1260002\n",
      "   1.        ]]\n",
      "(1000, 11) \n",
      "\n",
      "[[-1.07980097 -1.28844866 -0.96921961 ... -0.07886518 -0.87643651\n",
      "   1.        ]\n",
      " [ 2.40438778 -3.32292852  0.66547387 ...  0.47456144 -0.62825596\n",
      "  -1.        ]\n",
      " [-0.54582793  0.77878532  0.08592099 ...  1.21068115 -0.25649693\n",
      "  -1.        ]\n",
      " ...\n",
      " [ 2.24361791  1.92961334 -0.32604635 ...  0.10112766 -0.87566657\n",
      "   1.        ]\n",
      " [ 3.33904654  1.92063043 -1.55614559 ... -0.51534274  1.11347745\n",
      "  -1.        ]\n",
      " [-1.71472981 -0.67902764  0.37347159 ...  0.38208181 -0.11064126\n",
      "   1.        ]]\n",
      "(1000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(data_train)\n",
    "print(data_train.shape, '\\n')\n",
    "print(data_test)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self, feature, theta):\n",
    "        self.feature = feature\n",
    "        self.theta = theta\n",
    "\n",
    "    def match(self, example):\n",
    "        return example[self.feature] > self.theta\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Is feature %s > %s ?\" % (self.feature, str(self.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question):  \n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    counts = {}\n",
    "    for row in rows:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(rows):\n",
    "\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    majority = max(counts, key=counts.get)\n",
    "    prob = counts[majority] / float(len(rows))\n",
    "    impurity -= prob\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thetas(rows, col):\n",
    "    values =  sorted(set([row[col] for row in rows]))\n",
    "    thetas = []\n",
    "    for i in range(len(values)-1):\n",
    "        thetas.append( (values[i]+values[i+1])/2 )\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows, impurity_function):\n",
    "    best_error = len(rows)\n",
    "    best_question = None\n",
    "    n_features = len(rows[0]) - 1\n",
    "\n",
    "    for col in range(n_features):\n",
    "        thetas = get_thetas(rows, col)\n",
    "        for val in thetas:\n",
    "            question = Question(col, val)\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            error = len(true_rows)*impurity_function(true_rows) + len(false_rows)*impurity_function(false_rows)\n",
    "            if(error < best_error):\n",
    "                best_error, best_question = error, question\n",
    "\n",
    "    return best_error, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows, impurity_function):\n",
    "    # Base case, one class\n",
    "    if (len(class_counts(rows)) == 1):\n",
    "        return Leaf(rows)\n",
    "\n",
    "    err, question = find_best_split(rows, impurity_function)\n",
    "\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    true_branch = build_tree(true_rows, impurity_function)\n",
    "    false_branch = build_tree(false_rows, impurity_function)\n",
    "\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Tree:\n",
    "    def __init__(self, root=None):\n",
    "        self.root = root\n",
    "    def check_root(self):\n",
    "        return self.root==None\n",
    "    def fit(self, rows, impurity_function):\n",
    "        if (len(class_counts(rows)) == 1):\n",
    "            self.root = Leaf(rows)\n",
    "        else:\n",
    "            self.root = build_tree(rows, impurity_function)\n",
    "    \n",
    "    def _classify(self, row, node):\n",
    "        if isinstance(node, Leaf):\n",
    "            return node.predictions\n",
    "        if node.question.match(row):\n",
    "            return self._classify(row, node.true_branch)\n",
    "        else:\n",
    "            return self._classify(row, node.false_branch)\n",
    "    \n",
    "    def predict(self, rows):\n",
    "        pr = []\n",
    "        for row in rows:\n",
    "            cl = self._classify(row, self.root)\n",
    "            pr.append(max(cl, key=cl.get))\n",
    "        return pr\n",
    "    \n",
    "    def score(self, rows):\n",
    "        wrong = 0\n",
    "        for row in rows:\n",
    "            cl = self._classify(row, self.root)\n",
    "            pr = max(cl, key=cl.get)\n",
    "            if (row[-1] != pr):\n",
    "                wrong += 1\n",
    "        return wrong/len(rows)\n",
    "    \n",
    "    def _print_tree(self, node, spacing=\"\"):\n",
    "        if isinstance(node, Leaf):\n",
    "            print (spacing + \"Predict\", node.predictions)\n",
    "            return\n",
    "        \n",
    "        print (spacing + str(node.question))\n",
    "\n",
    "        print (spacing + '--> True:')\n",
    "        self._print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "        print (spacing + '--> False:')\n",
    "        self._print_tree(node.false_branch, spacing + \"  \")\n",
    "        \n",
    "    def print_tree(self):\n",
    "        self._print_tree(self.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.166"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = Decision_Tree()\n",
    "dt.fit(data_train, gini)\n",
    "dt.score(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is feature 5 > -1.3180367635499999 ?\n",
      "--> True:\n",
      "  Is feature 9 > 0.97445967225 ?\n",
      "  --> True:\n",
      "    Is feature 2 > 1.82562346345 ?\n",
      "    --> True:\n",
      "      Is feature 0 > 0.23738037289999997 ?\n",
      "      --> True:\n",
      "        Is feature 5 > 0.48950835115 ?\n",
      "        --> True:\n",
      "          Predict {-1.0: 3}\n",
      "        --> False:\n",
      "          Predict {1.0: 9}\n",
      "      --> False:\n",
      "        Predict {-1.0: 7}\n",
      "    --> False:\n",
      "      Is feature 4 > -1.33348060355 ?\n",
      "      --> True:\n",
      "        Is feature 0 > -1.4231283196 ?\n",
      "        --> True:\n",
      "          Predict {-1.0: 55}\n",
      "        --> False:\n",
      "          Is feature 0 > -1.6852853846 ?\n",
      "          --> True:\n",
      "            Predict {1.0: 1}\n",
      "          --> False:\n",
      "            Is feature 2 > -1.4076548431 ?\n",
      "            --> True:\n",
      "              Predict {-1.0: 22}\n",
      "            --> False:\n",
      "              Is feature 0 > -2.8119415982 ?\n",
      "              --> True:\n",
      "                Predict {1.0: 1}\n",
      "              --> False:\n",
      "                Predict {-1.0: 3}\n",
      "      --> False:\n",
      "        Is feature 7 > 0.0983719705 ?\n",
      "        --> True:\n",
      "          Is feature 1 > 2.4975693353 ?\n",
      "          --> True:\n",
      "            Predict {-1.0: 1}\n",
      "          --> False:\n",
      "            Predict {1.0: 4}\n",
      "        --> False:\n",
      "          Predict {-1.0: 10}\n",
      "  --> False:\n",
      "    Is feature 9 > -0.91488512955 ?\n",
      "    --> True:\n",
      "      Is feature 2 > -1.81988048505 ?\n",
      "      --> True:\n",
      "        Is feature 8 > -1.1820701436499998 ?\n",
      "        --> True:\n",
      "          Is feature 1 > -2.8221521085 ?\n",
      "          --> True:\n",
      "            Is feature 7 > -1.39131126785 ?\n",
      "            --> True:\n",
      "              Is feature 3 > -1.714619438 ?\n",
      "              --> True:\n",
      "                Is feature 8 > 1.4683165311500002 ?\n",
      "                --> True:\n",
      "                  Is feature 3 > -1.4056306565 ?\n",
      "                  --> True:\n",
      "                    Predict {-1.0: 12}\n",
      "                  --> False:\n",
      "                    Predict {1.0: 1}\n",
      "                --> False:\n",
      "                  Is feature 6 > 1.9143213811 ?\n",
      "                  --> True:\n",
      "                    Is feature 0 > 2.9626537703 ?\n",
      "                    --> True:\n",
      "                      Predict {1.0: 1}\n",
      "                    --> False:\n",
      "                      Predict {-1.0: 9}\n",
      "                  --> False:\n",
      "                    Is feature 1 > 3.39886832065 ?\n",
      "                    --> True:\n",
      "                      Is feature 0 > 2.47067108935 ?\n",
      "                      --> True:\n",
      "                        Is feature 2 > 0.46555869555 ?\n",
      "                        --> True:\n",
      "                          Predict {-1.0: 1}\n",
      "                        --> False:\n",
      "                          Predict {1.0: 7}\n",
      "                      --> False:\n",
      "                        Predict {-1.0: 10}\n",
      "                    --> False:\n",
      "                      Is feature 5 > 1.0778208934 ?\n",
      "                      --> True:\n",
      "                        Is feature 4 > 1.05299247505 ?\n",
      "                        --> True:\n",
      "                          Is feature 0 > -1.7385485776 ?\n",
      "                          --> True:\n",
      "                            Predict {1.0: 2}\n",
      "                          --> False:\n",
      "                            Predict {-1.0: 1}\n",
      "                        --> False:\n",
      "                          Predict {-1.0: 9}\n",
      "                      --> False:\n",
      "                        Is feature 3 > 2.1607726173 ?\n",
      "                        --> True:\n",
      "                          Is feature 0 > 3.8043128574500003 ?\n",
      "                          --> True:\n",
      "                            Predict {1.0: 1}\n",
      "                          --> False:\n",
      "                            Predict {-1.0: 7}\n",
      "                        --> False:\n",
      "                          Is feature 4 > 2.46934275775 ?\n",
      "                          --> True:\n",
      "                            Predict {-1.0: 2}\n",
      "                          --> False:\n",
      "                            Is feature 2 > 1.45947287655 ?\n",
      "                            --> True:\n",
      "                              Is feature 4 > -1.4233061818000001 ?\n",
      "                              --> True:\n",
      "                                Is feature 5 > 0.5458372915 ?\n",
      "                                --> True:\n",
      "                                  Is feature 0 > -3.4079839872999997 ?\n",
      "                                  --> True:\n",
      "                                    Predict {-1.0: 3}\n",
      "                                  --> False:\n",
      "                                    Predict {1.0: 1}\n",
      "                                --> False:\n",
      "                                  Is feature 3 > -0.28382832075 ?\n",
      "                                  --> True:\n",
      "                                    Predict {1.0: 33}\n",
      "                                  --> False:\n",
      "                                    Is feature 9 > -0.46327087460000005 ?\n",
      "                                    --> True:\n",
      "                                      Is feature 2 > 2.54748963095 ?\n",
      "                                      --> True:\n",
      "                                        Predict {-1.0: 1}\n",
      "                                      --> False:\n",
      "                                        Predict {1.0: 8}\n",
      "                                    --> False:\n",
      "                                      Is feature 0 > -2.1034637447 ?\n",
      "                                      --> True:\n",
      "                                        Predict {-1.0: 4}\n",
      "                                      --> False:\n",
      "                                        Predict {1.0: 1}\n",
      "                              --> False:\n",
      "                                Predict {-1.0: 3}\n",
      "                            --> False:\n",
      "                              Is feature 0 > -4.12188064455 ?\n",
      "                              --> True:\n",
      "                                Is feature 6 > -2.1020912575499997 ?\n",
      "                                --> True:\n",
      "                                  Is feature 9 > 0.23768345575 ?\n",
      "                                  --> True:\n",
      "                                    Is feature 3 > 1.5807624176 ?\n",
      "                                    --> True:\n",
      "                                      Predict {-1.0: 2}\n",
      "                                    --> False:\n",
      "                                      Is feature 5 > -1.24865412895 ?\n",
      "                                      --> True:\n",
      "                                        Is feature 9 > 0.2408781388 ?\n",
      "                                        --> True:\n",
      "                                          Is feature 3 > -1.4828508461999999 ?\n",
      "                                          --> True:\n",
      "                                            Is feature 8 > -0.35124513815 ?\n",
      "                                            --> True:\n",
      "                                              Predict {1.0: 78}\n",
      "                                            --> False:\n",
      "                                              Is feature 0 > 3.0032687207 ?\n",
      "                                              --> True:\n",
      "                                                Predict {-1.0: 2}\n",
      "                                              --> False:\n",
      "                                                Is feature 3 > 1.029139469 ?\n",
      "                                                --> True:\n",
      "                                                  Predict {-1.0: 1}\n",
      "                                                --> False:\n",
      "                                                  Predict {1.0: 20}\n",
      "                                          --> False:\n",
      "                                            Is feature 0 > -0.8788343863500001 ?\n",
      "                                            --> True:\n",
      "                                              Is feature 1 > -0.350457684 ?\n",
      "                                              --> True:\n",
      "                                                Predict {-1.0: 3}\n",
      "                                              --> False:\n",
      "                                                Predict {1.0: 1}\n",
      "                                            --> False:\n",
      "                                              Predict {1.0: 4}\n",
      "                                        --> False:\n",
      "                                          Predict {-1.0: 1}\n",
      "                                      --> False:\n",
      "                                        Predict {-1.0: 1}\n",
      "                                  --> False:\n",
      "                                    Is feature 5 > -1.30758153075 ?\n",
      "                                    --> True:\n",
      "                                      Is feature 7 > 1.2749032677 ?\n",
      "                                      --> True:\n",
      "                                        Is feature 1 > 0.60559686 ?\n",
      "                                        --> True:\n",
      "                                          Predict {-1.0: 1}\n",
      "                                        --> False:\n",
      "                                          Predict {1.0: 6}\n",
      "                                      --> False:\n",
      "                                        Is feature 2 > -1.27641140695 ?\n",
      "                                        --> True:\n",
      "                                          Predict {1.0: 238}\n",
      "                                        --> False:\n",
      "                                          Is feature 2 > -1.2883350149 ?\n",
      "                                          --> True:\n",
      "                                            Predict {-1.0: 1}\n",
      "                                          --> False:\n",
      "                                            Predict {1.0: 30}\n",
      "                                    --> False:\n",
      "                                      Is feature 0 > 1.01077211805 ?\n",
      "                                      --> True:\n",
      "                                        Predict {1.0: 1}\n",
      "                                      --> False:\n",
      "                                        Predict {-1.0: 1}\n",
      "                                --> False:\n",
      "                                  Predict {-1.0: 1}\n",
      "                              --> False:\n",
      "                                Predict {-1.0: 2}\n",
      "              --> False:\n",
      "                Is feature 0 > -1.5316582043 ?\n",
      "                --> True:\n",
      "                  Predict {-1.0: 22}\n",
      "                --> False:\n",
      "                  Is feature 1 > 0.6615898043499999 ?\n",
      "                  --> True:\n",
      "                    Predict {1.0: 13}\n",
      "                  --> False:\n",
      "                    Predict {-1.0: 2}\n",
      "            --> False:\n",
      "              Is feature 4 > 0.06173246545000001 ?\n",
      "              --> True:\n",
      "                Is feature 5 > 0.4525497187 ?\n",
      "                --> True:\n",
      "                  Predict {-1.0: 2}\n",
      "                --> False:\n",
      "                  Predict {1.0: 6}\n",
      "              --> False:\n",
      "                Is feature 6 > 2.6179218512 ?\n",
      "                --> True:\n",
      "                  Predict {1.0: 1}\n",
      "                --> False:\n",
      "                  Is feature 0 > 0.76175511055 ?\n",
      "                  --> True:\n",
      "                    Predict {-1.0: 17}\n",
      "                  --> False:\n",
      "                    Is feature 4 > -1.2293173487 ?\n",
      "                    --> True:\n",
      "                      Predict {-1.0: 6}\n",
      "                    --> False:\n",
      "                      Is feature 2 > 1.39067134695 ?\n",
      "                      --> True:\n",
      "                        Predict {-1.0: 1}\n",
      "                      --> False:\n",
      "                        Predict {1.0: 2}\n",
      "          --> False:\n",
      "            Is feature 8 > -0.031918811049999996 ?\n",
      "            --> True:\n",
      "              Predict {-1.0: 17}\n",
      "            --> False:\n",
      "              Is feature 2 > 0.6199652684 ?\n",
      "              --> True:\n",
      "                Predict {1.0: 1}\n",
      "              --> False:\n",
      "                Predict {-1.0: 2}\n",
      "        --> False:\n",
      "          Is feature 1 > 3.4415458211 ?\n",
      "          --> True:\n",
      "            Predict {1.0: 2}\n",
      "          --> False:\n",
      "            Is feature 1 > 2.35346801755 ?\n",
      "            --> True:\n",
      "              Is feature 0 > -2.28774326975 ?\n",
      "              --> True:\n",
      "                Predict {-1.0: 2}\n",
      "              --> False:\n",
      "                Predict {1.0: 1}\n",
      "            --> False:\n",
      "              Predict {-1.0: 28}\n",
      "      --> False:\n",
      "        Is feature 8 > -0.20826915094999998 ?\n",
      "        --> True:\n",
      "          Is feature 3 > -0.0781653956 ?\n",
      "          --> True:\n",
      "            Is feature 1 > 0.83351775205 ?\n",
      "            --> True:\n",
      "              Predict {-1.0: 3}\n",
      "            --> False:\n",
      "              Is feature 1 > -1.66527019695 ?\n",
      "              --> True:\n",
      "                Is feature 2 > -3.0599340413 ?\n",
      "                --> True:\n",
      "                  Predict {1.0: 10}\n",
      "                --> False:\n",
      "                  Predict {-1.0: 2}\n",
      "              --> False:\n",
      "                Predict {-1.0: 2}\n",
      "          --> False:\n",
      "            Is feature 0 > 1.9508574211999998 ?\n",
      "            --> True:\n",
      "              Predict {1.0: 1}\n",
      "            --> False:\n",
      "              Is feature 4 > -1.3580952126999999 ?\n",
      "              --> True:\n",
      "                Predict {-1.0: 16}\n",
      "              --> False:\n",
      "                Is feature 0 > 0.7516766557500001 ?\n",
      "                --> True:\n",
      "                  Predict {1.0: 1}\n",
      "                --> False:\n",
      "                  Predict {-1.0: 1}\n",
      "        --> False:\n",
      "          Is feature 9 > 0.8556466194000001 ?\n",
      "          --> True:\n",
      "            Is feature 0 > -0.39698778435000004 ?\n",
      "            --> True:\n",
      "              Predict {-1.0: 1}\n",
      "            --> False:\n",
      "              Predict {1.0: 1}\n",
      "          --> False:\n",
      "            Predict {-1.0: 26}\n",
      "    --> False:\n",
      "      Is feature 0 > -2.74956431915 ?\n",
      "      --> True:\n",
      "        Is feature 6 > 0.1563869027 ?\n",
      "        --> True:\n",
      "          Predict {-1.0: 40}\n",
      "        --> False:\n",
      "          Is feature 5 > 0.75785064205 ?\n",
      "          --> True:\n",
      "            Predict {-1.0: 16}\n",
      "          --> False:\n",
      "            Is feature 9 > -1.4417502179000001 ?\n",
      "            --> True:\n",
      "              Is feature 1 > -1.9304799539 ?\n",
      "              --> True:\n",
      "                Is feature 1 > -0.5390271203 ?\n",
      "                --> True:\n",
      "                  Is feature 0 > 2.1354616703 ?\n",
      "                  --> True:\n",
      "                    Predict {1.0: 1}\n",
      "                  --> False:\n",
      "                    Predict {-1.0: 3}\n",
      "                --> False:\n",
      "                  Predict {1.0: 8}\n",
      "              --> False:\n",
      "                Predict {-1.0: 3}\n",
      "            --> False:\n",
      "              Predict {-1.0: 9}\n",
      "      --> False:\n",
      "        Predict {1.0: 4}\n",
      "--> False:\n",
      "  Predict {-1.0: 100}\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"pred.csv\",  \n",
    "           dt.predict(data_test), \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_forest:\n",
    "    def __init__(self, n_trees=2000):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []\n",
    "        self.train = None\n",
    "        self.oob_i_tree = [] # for Q18\n",
    "    \n",
    "    def fit(self, rows):\n",
    "        self.train = np.array(rows)\n",
    "        self.oob_i_tree = [[] for i in range(len(self.train))]\n",
    "        for i in range(self.n_trees):\n",
    "            # bootstrapping\n",
    "            index = [i for i in range(len(self.train))]\n",
    "            i_bag = choices(index, k=int(len(self.train)*0.5))\n",
    "            i_oob = [item for item in index if item not in i_bag]\n",
    "            \n",
    "            # for Q18\n",
    "            for j in i_oob:\n",
    "                self.oob_i_tree[j].append(i)\n",
    "            bag = self.train[i_bag]\n",
    "            \n",
    "            dt = Decision_Tree()\n",
    "            dt.fit(bag, gini)\n",
    "\n",
    "            self.trees.append(dt)\n",
    "\n",
    "    # for Q15\n",
    "    def avg_score(self, rows):\n",
    "        score = 0\n",
    "        for tree in self.trees:\n",
    "            score += tree.score(rows)\n",
    "        return (score/self.n_trees)\n",
    "    \n",
    "    # for Q16, 17\n",
    "    def score(self, rows):\n",
    "        sc = np.array([0.0 for i in range(len(rows))])\n",
    "        for tree in self.trees:\n",
    "            sc += np.array(tree.predict(rows))\n",
    "        for n, i in enumerate(sc):\n",
    "            if i > 0:\n",
    "                sc[n] = 1.0\n",
    "            else:\n",
    "                sc[n] = -1.0\n",
    "        \n",
    "        wrong = 0\n",
    "        for tr, pr in zip(rows, sc):\n",
    "            if (tr[-1] != pr):\n",
    "                wrong += 1\n",
    "        \n",
    "        return wrong/len(rows)\n",
    "    \n",
    "    def oob_score(self):\n",
    "        error = 0\n",
    "        for i in range(len(self.train)):\n",
    "            if self.oob_i_tree[i] == []:\n",
    "                error += int(self.train[i][-1] == -1)\n",
    "                continue\n",
    "            \n",
    "            pr = 0\n",
    "            for j in self.oob_i_tree[i]:\n",
    "                pr += self.trees[j].predict([self.train[i]])[0]\n",
    "            if pr > 0:\n",
    "                pr = 1\n",
    "            else:\n",
    "                pr = -1\n",
    "            error += int(self.train[i][-1] == pr)\n",
    "        return error/len(self.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616239999999999\n",
      "0.009\n",
      "0.153\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "rf = Random_forest(2000)\n",
    "rf.fit(data_train)\n",
    "print(rf.avg_score(data_test))\n",
    "print(rf.score(data_train))\n",
    "print(rf.score(data_test))\n",
    "print(rf.oob_score())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
